I200430 17:13:46.521126 1 util/log/clog.go:1196  [config] file created at: 2020/04/30 17:13:46
I200430 17:13:46.521126 1 util/log/clog.go:1196  [config] running on machine: b5564a6f4539
I200430 17:13:46.521126 1 util/log/clog.go:1196  [config] binary: CockroachDB CCL v19.2.5 (x86_64-unknown-linux-gnu, built 2020/03/16 18:27:12, go1.12.12)
I200430 17:13:46.521126 1 util/log/clog.go:1196  [config] arguments: [/cockroach/cockroach start --insecure]
I200430 17:13:46.521126 1 util/log/clog.go:1196  line format: [IWEF]yymmdd hh:mm:ss.uuuuuu goid file:line msg utf8=✓
I200430 17:13:46.521125 1 cli/start.go:1144  logging to directory /cockroach/cockroach-data/logs
W200430 17:13:46.539508 1 cli/start.go:1182  RUNNING IN INSECURE MODE!

- Your cluster is open for any client that can access <all your IP addresses>.
- Any user, even root, can log in without providing a password.
- Any user, connecting as root, can read or write any data in your cluster.
- There is no network encryption nor authentication, and thus no confidentiality.

Check out how to secure your cluster: https://www.cockroachlabs.com/docs/v19.2/secure-a-cluster.html
I200430 17:13:46.540947 1 server/status/recorder.go:597  available memory from cgroups (8.0 EiB) is unsupported, using system memory 2.9 GiB instead: 
W200430 17:13:46.541996 1 cli/start.go:1052  Using the default setting for --cache (128 MiB).
  A significantly larger value is usually needed for good performance.
  If you have a dedicated server a reasonable setting is --cache=.25 (749 MiB).
I200430 17:13:46.544860 1 server/status/recorder.go:597  available memory from cgroups (8.0 EiB) is unsupported, using system memory 2.9 GiB instead: 
W200430 17:13:46.544912 1 cli/start.go:1065  Using the default setting for --max-sql-memory (128 MiB).
  A significantly larger value is usually needed in production.
  If you have a dedicated server a reasonable setting is --max-sql-memory=.25 (749 MiB).
I200430 17:13:46.545307 1 server/status/recorder.go:597  available memory from cgroups (8.0 EiB) is unsupported, using system memory 2.9 GiB instead: 
I200430 17:13:46.545341 1 cli/start.go:1196  CockroachDB CCL v19.2.5 (x86_64-unknown-linux-gnu, built 2020/03/16 18:27:12, go1.12.12)
W200430 17:13:49.095547 1 cli/start.go:511  running 'cockroach start' without --join is deprecated.
Consider using 'cockroach start-single-node' or 'cockroach init' instead.
I200430 17:13:49.187453 1 server/status/recorder.go:597  available memory from cgroups (8.0 EiB) is unsupported, using system memory 2.9 GiB instead: 
I200430 17:13:49.187506 1 server/config.go:394  system total memory: 2.9 GiB
I200430 17:13:49.187752 1 server/config.go:396  server configuration:
max offset             500000000
cache size             128 MiB
SQL memory pool size   128 MiB
scan interval          10m0s
scan min idle time     10ms
scan max idle time     1s
event log enabled      true
I200430 17:13:49.187799 1 cli/start.go:1030  using local environment variables: COCKROACH_CHANNEL=official-docker
I200430 17:13:49.191850 1 cli/start.go:1037  process identity: uid 0 euid 0 gid 0 egid 0
I200430 17:13:49.192027 1 cli/start.go:644  starting cockroach node
I200430 17:13:49.308798 34 storage/engine/rocksdb.go:622  opening rocksdb instance at "/cockroach/cockroach-data/cockroach-temp930428700"
I200430 17:13:50.898861 34 server/server.go:928  [n?] monitoring forward clock jumps based on server.clock.forward_jump_check_enabled
I200430 17:13:51.009288 34 storage/engine/rocksdb.go:622  opening rocksdb instance at "/cockroach/cockroach-data"
I200430 17:13:53.582603 34 server/config.go:502  [n?] 1 storage engine initialized
I200430 17:13:53.582633 34 server/config.go:505  [n?] RocksDB cache size: 128 MiB
I200430 17:13:53.583033 34 server/config.go:505  [n?] store 0: RocksDB, max size 0 B, max open file limit 1043576
W200430 17:13:53.714535 34 cli/start.go:996  neither --listen-addr nor --advertise-addr was specified.
The server will advertise "b5564a6f4539" to other nodes, is this routable?

Consider using:
- for local-only servers:  --listen-addr=localhost
- for multi-node clusters: --advertise-addr=<host/IP addr>
I200430 17:13:53.723170 34 gossip/gossip.go:394  [n1] NodeDescriptor set to node_id:1 address:<network_field:"tcp" address_field:"b5564a6f4539:26257" > attrs:<> locality:<> ServerVersion:<major_val:19 minor_val:2 patch:0 unstable:0 > build_tag:"v19.2.5" started_at:1588266833722992865 cluster_name:"" sql_address:<network_field:"tcp" address_field:"b5564a6f4539:26257" > 
W200430 17:13:55.084071 130 storage/replica_range_lease.go:554  can't determine lease status due to node liveness error: node not in the liveness table
github.com/cockroachdb/cockroach/pkg/storage.init.ializers
	/go/src/github.com/cockroachdb/cockroach/pkg/storage/node_liveness.go:44
runtime.main
	/usr/local/go/src/runtime/proc.go:188
runtime.goexit
	/usr/local/go/src/runtime/asm_amd64.s:1337
W200430 17:13:55.084379 130 storage/store.go:1530  [n1,s1,r6/1:/Table/{SystemCon…-11}] could not gossip system config: [NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown
W200430 17:13:55.143521 130 storage/store.go:1530  [n1,s1,r6/1:/Table/{SystemCon…-11}] could not gossip system config: [NotLeaseHolderError] r6: replica (n1,s1):1 not lease holder; lease holder unknown
I200430 17:13:55.668228 79 gossip/gossip.go:1531  [n1] node has connected to cluster via gossip
I200430 17:13:56.387403 34 server/node.go:431  [n1] initialized store [n1,s1]: disk (capacity=60 TiB, available=28 TiB, used=61 MiB, logicalBytes=306 MiB), ranges=38, leases=2, queries=0.00, writes=0.00, bytesPerReplica={p10=0.00 p25=0.00 p50=9492.00 p75=4425254.00 p90=44439395.00 pMax=63459387.00}, writesPerReplica={p10=0.00 p25=0.00 p50=0.00 p75=0.00 p90=0.00 pMax=0.00}
I200430 17:13:56.387588 34 storage/stores.go:240  [n1] read 1 node addresses from persistent storage
I200430 17:13:56.387739 34 storage/stores.go:259  [n1] wrote 2 node addresses to persistent storage
I200430 17:13:56.387919 34 server/node.go:645  [n1] connecting to gossip network to verify cluster ID...
I200430 17:13:56.387981 34 server/node.go:665  [n1] node connected via gossip and verified as part of cluster "ea35b6ad-0215-43e2-94d0-3ce953db1cc1"
I200430 17:13:56.388071 34 server/node.go:512  [n1] node=1: started with [<no-attributes>=/cockroach/cockroach-data] engine(s) and attributes []
I200430 17:13:56.399310 34 server/server.go:1514  [n1] starting http server at [::]:8080 (use: b5564a6f4539:8080)
I200430 17:13:56.399355 34 server/server.go:1521  [n1] starting grpc/postgres server at [::]:26257
I200430 17:13:56.399600 34 server/server.go:1522  [n1] advertising CockroachDB node at b5564a6f4539:26257
I200430 17:13:56.605798 157 gossip/client.go:124  [n1] started gossip client to c4ff208bedd9:26257
W200430 17:13:56.889983 145 storage/node_liveness.go:559  [n1,s1,r6/1:/Table/{SystemCon…-11}] slow heartbeat took 1.7s
I200430 17:13:56.906911 206 storage/node_liveness.go:474  [n1,liveness-hb] heartbeat failed on epoch increment; retrying
I200430 17:13:57.846049 79 storage/stores.go:259  [n1] wrote 1 node addresses to persistent storage
W200430 17:13:57.902160 95 storage/store_raft.go:514  [n1,s1,r54/1:/System/tsd/cr.node.sql.…] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=1]
W200430 17:13:57.902236 97 storage/store_raft.go:514  [n1,s1,r27/1:/{Table/55-Max}] handle raft ready: 0.7s [applied=3, batches=2, state_assertions=1]
W200430 17:13:57.945357 119 storage/store_raft.go:514  [n1,s1,r99/1:/System/tsd/cr.node.{no…-sq…}] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=1]
W200430 17:13:58.079793 118 storage/store_raft.go:514  [n1,s1,r32/1:/System/tsd/cr.store.{kv…-ra…}] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W200430 17:13:58.132378 94 storage/store_raft.go:514  [n1,s1,r125/1:/System/tsd/cr.node.s{ql…-ys…}] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W200430 17:13:58.290440 120 storage/store_raft.go:514  [n1,s1,r52/1:/System/tsd/cr.node.sql.mem.…] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
I200430 17:13:59.780155 34 server/server.go:1590  [n1] done ensuring all necessary migrations have run
I200430 17:13:59.780217 34 server/server.go:1841  [n1] serving sql connections
I200430 17:13:59.783978 34 cli/start.go:803  [config] clusterID: ea35b6ad-0215-43e2-94d0-3ce953db1cc1
I200430 17:13:59.787914 34 cli/start.go:812  node startup completed:
CockroachDB node starting at 2020-04-30 17:13:59.780268656 +0000 UTC (took 13.3s)
build:               CCL v19.2.5 @ 2020/03/16 18:27:12 (go1.12.12)
webui:               http://b5564a6f4539:8080
sql:                 postgresql://root@b5564a6f4539:26257?sslmode=disable
RPC client flags:    /cockroach/cockroach <client cmd> --host=b5564a6f4539:26257 --insecure
logs:                /cockroach/cockroach-data/logs
temp dir:            /cockroach/cockroach-data/cockroach-temp930428700
external I/O path:   /cockroach/cockroach-data/extern
store[0]:            path=/cockroach/cockroach-data
status:              restarted pre-existing node
clusterID:           ea35b6ad-0215-43e2-94d0-3ce953db1cc1
nodeID:              1
I200430 17:14:00.156563 410 server/server_update.go:53  [n1] no need to upgrade, cluster already at the newest version
I200430 17:14:00.174151 412 sql/event_log.go:130  [n1] Event: "node_restart", target: 1, info: {Descriptor:{NodeID:1 Address:b5564a6f4539:26257 Attrs: Locality: ServerVersion:19.2 BuildTag:v19.2.5 StartedAt:1588266833722992865 LocalityAddress:[] ClusterName: SQLAddress:b5564a6f4539:26257} ClusterID:ea35b6ad-0215-43e2-94d0-3ce953db1cc1 StartedAt:1588266833722992865 LastUp:1588266526029568957}
I200430 17:14:06.614972 200 server/status/runtime.go:498  [n1] runtime stats: 190 MiB RSS, 164 goroutines, 112 MiB/10 MiB/135 MiB GO alloc/idle/total, 36 MiB/43 MiB CGO alloc/total, 0.0 CGO/sec, 0.0/0.0 %(u/s)time, 0.0 %gc (9x), 189 KiB/97 KiB (r/w)net
W200430 17:14:10.254856 118 storage/store_raft.go:514  [n1,s1,r101/1:/System{/tsd/cr.s…-tse}] handle raft ready: 0.5s [applied=1, batches=1, state_assertions=0]
W200430 17:14:10.701386 94 storage/store_raft.go:514  [n1,s1,r52/1:/System/tsd/cr.node.sql.mem.…] handle raft ready: 0.9s [applied=1, batches=1, state_assertions=0]
W200430 17:14:13.598612 404 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:1 Category:METRICS Description:ranges.underreplicated Value:38} {StoreID:0 Category:METRICS Description:liveness.heartbeatfailures Value:1}]}
I200430 17:14:16.472586 615 storage/replica_consistency.go:229  [n1,consistencyChecker,s1,r52/1:/System/tsd/cr.node.sql.mem.…] triggering stats recomputation to resolve delta of {ContainsEstimates:true LastUpdateNanos:1588266836978918679 IntentAge:0 GCBytesAge:0 LiveBytes:15814922 LiveCount:-2470 KeyBytes:-115928 KeyCount:-2470 ValBytes:15930850 ValCount:-2470 IntentBytes:0 IntentCount:0 SysBytes:0 SysCount:0}
I200430 17:14:16.709620 200 server/status/runtime.go:498  [n1] runtime stats: 268 MiB RSS, 158 goroutines, 86 MiB/96 MiB/202 MiB GO alloc/idle/total, 68 MiB/80 MiB CGO alloc/total, 871.7 CGO/sec, 13.2/6.2 %(u/s)time, 1.0 %gc (2x), 75 KiB/39 KiB (r/w)net
I200430 17:14:17.931634 195 storage/store.go:2364  [n1,s1] sstables (read amplification = 2):
0 [ 606K 1 ]: 606K
6 [  31M 8 ]: 4M[7] 3M
I200430 17:14:17.931771 195 storage/store.go:2365  [n1,s1] 
** Compaction Stats [default] **
Level    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  L0      1/0   605.52 KB   0.5      0.0     0.0      0.0       0.0      0.0       0.0   1.0      0.0      0.7      0.84              0.00         1    0.840       0      0
  L6      8/0   30.94 MB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0
 Sum      9/0   31.53 MB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   1.0      0.0      0.7      0.84              0.00         1    0.840       0      0
 Int      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   1.0      0.0      0.7      0.84              0.00         1    0.840       0      0

** Compaction Stats [default] **
Priority    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
User      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.7      0.84              0.00         1    0.840       0      0
Uptime(secs): 26.6 total, 26.6 interval
Flush(GB): cumulative 0.001, interval 0.001
AddFile(GB): cumulative 0.000, interval 0.000
AddFile(Total Files): cumulative 0, interval 0
AddFile(L0 Files): cumulative 0, interval 0
AddFile(Keys): cumulative 0, interval 0
Cumulative compaction: 0.00 GB write, 0.02 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.8 seconds
Interval compaction: 0.00 GB write, 0.02 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.8 seconds
Stalls(count): 0 level0_slowdown, 0 level0_slowdown_with_compaction, 0 level0_numfiles, 0 level0_numfiles_with_compaction, 0 stop for pending_compaction_bytes, 0 slowdown for pending_compaction_bytes, 0 memtable_compaction, 0 memtable_slowdown, interval 0 total count
estimated_pending_compaction_bytes: 0 B
W200430 17:14:20.599795 404 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:1 Category:METRICS Description:ranges.underreplicated Value:38}]}
I200430 17:14:26.786912 200 server/status/runtime.go:498  [n1] runtime stats: 300 MiB RSS, 159 goroutines, 111 MiB/73 MiB/202 MiB GO alloc/idle/total, 83 MiB/104 MiB CGO alloc/total, 2155.2 CGO/sec, 15.9/8.9 %(u/s)time, 0.0 %gc (2x), 36 KiB/21 KiB (r/w)net
W200430 17:14:30.466621 94 storage/engine/rocksdb.go:2076  batch [334/37436/0] commit took 642.175572ms (>= warning threshold 500ms)
W200430 17:14:30.495719 121 storage/store_raft.go:514  [n1,s1,r70/1:/System/tsd/cr.{node.…-store…}] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W200430 17:14:30.495863 119 storage/store_raft.go:514  [n1,s1,r55/1:/System/tsd/cr.store.{ra…-tx…}] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W200430 17:14:30.502409 114 storage/store_raft.go:514  [n1,s1,r96/1:/System/tsd/cr.node.{sy…-tx…}] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W200430 17:14:30.502525 122 storage/store_raft.go:514  [n1,s1,r4/1:/System/tsd{-/cr.nod…}] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W200430 17:14:30.502556 124 storage/store_raft.go:514  [n1,s1,r52/1:/System/tsd/cr.node.sql.mem.…] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W200430 17:14:30.502599 97 storage/store_raft.go:514  [n1,s1,r32/1:/System/tsd/cr.store.{kv…-ra…}] handle raft ready: 0.8s [applied=1, batches=1, state_assertions=0]
W200430 17:14:30.502647 118 storage/store_raft.go:514  [n1,s1,r125/1:/System/tsd/cr.node.s{ql…-ys…}] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W200430 17:14:30.518828 94 storage/store_raft.go:514  [n1,s1,r2/1:/System/NodeLiveness{-Max}] handle raft ready: 0.7s [applied=1, batches=1, state_assertions=0]
W200430 17:14:35.318581 404 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:1 Category:METRICS Description:ranges.underreplicated Value:38}]}
I200430 17:14:36.737404 200 server/status/runtime.go:498  [n1] runtime stats: 304 MiB RSS, 158 goroutines, 108 MiB/75 MiB/202 MiB GO alloc/idle/total, 84 MiB/107 MiB CGO alloc/total, 91.9 CGO/sec, 12.7/6.7 %(u/s)time, 0.0 %gc (1x), 37 KiB/24 KiB (r/w)net
W200430 17:14:40.210540 404 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:1 Category:METRICS Description:ranges.underreplicated Value:38}]}
I200430 17:14:46.730408 200 server/status/runtime.go:498  [n1] runtime stats: 318 MiB RSS, 158 goroutines, 147 MiB/36 MiB/202 MiB GO alloc/idle/total, 91 MiB/118 MiB CGO alloc/total, 2315.6 CGO/sec, 21.5/10.8 %(u/s)time, 0.2 %gc (2x), 32 KiB/14 KiB (r/w)net
W200430 17:14:50.468493 404 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:1 Category:METRICS Description:ranges.underreplicated Value:38}]}
I200430 17:14:56.352354 196 gossip/gossip.go:566  [n1] gossip status (ok, 2 nodes)
gossip client (1/3 cur/max conns)
  2: c4ff208bedd9:26257 (1m0s: infos 207/37 sent/received, bytes 48186B/9666B sent/received)
gossip server (0/3 cur/max conns, infos 220/48 sent/received, bytes 49912B/11527B sent/received)
gossip connectivity
  n1 [sentinel];
  n1 -> n2;
I200430 17:14:56.721618 200 server/status/runtime.go:498  [n1] runtime stats: 319 MiB RSS, 157 goroutines, 101 MiB/83 MiB/202 MiB GO alloc/idle/total, 90 MiB/119 MiB CGO alloc/total, 754.1 CGO/sec, 6.0/4.0 %(u/s)time, 0.0 %gc (1x), 33 KiB/15 KiB (r/w)net
I200430 17:14:59.207474 1 cli/start.go:865  received signal 'terminated'
I200430 17:14:59.211657 1 cli/start.go:930  initiating graceful shutdown of server
W200430 17:14:59.561375 79 gossip/gossip.go:1517  [n1] no incoming or outgoing connections
W200430 17:14:59.596549 343 vendor/google.golang.org/grpc/clientconn.go:1206  grpc: addrConn.createTransport failed to connect to {c4ff208bedd9:26257 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W200430 17:14:59.596671 168 vendor/google.golang.org/grpc/clientconn.go:1206  grpc: addrConn.createTransport failed to connect to {c4ff208bedd9:26257 0  <nil>}. Err :connection error: desc = "transport: Error while dialing cannot reuse client connection". Reconnecting...
W200430 17:14:59.621842 1966 vendor/google.golang.org/grpc/clientconn.go:1206  grpc: addrConn.createTransport failed to connect to {c4ff208bedd9:26257 0  <nil>}. Err :connection error: desc = "transport: Error while dialing dial tcp 192.168.208.7:26257: connect: connection refused". Reconnecting...
I200430 17:14:59.629227 1975 vendor/github.com/cockroachdb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: gossip [::]:26257->c4ff208bedd9:26257 tripped: initial connection heartbeat failed: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = "transport: Error while dialing dial tcp 192.168.208.7:26257: connect: connection refused"
I200430 17:14:59.647029 1975 vendor/github.com/cockroachdb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: gossip [::]:26257->c4ff208bedd9:26257 event: BreakerTripped
W200430 17:14:59.649206 1975 gossip/client.go:118  [n1] failed to start gossip client to c4ff208bedd9:26257: initial connection heartbeat failed: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = "transport: Error while dialing dial tcp 192.168.208.7:26257: connect: connection refused"
W200430 17:14:59.659287 1990 vendor/google.golang.org/grpc/clientconn.go:1206  grpc: addrConn.createTransport failed to connect to {c4ff208bedd9:26257 0  <nil>}. Err :connection error: desc = "transport: Error while dialing dial tcp 192.168.208.7:26257: connect: connection refused". Reconnecting...
I200430 17:14:59.677301 1987 vendor/github.com/cockroachdb/circuitbreaker/circuitbreaker.go:322  [n1] circuitbreaker: rpc [::]:26257 [n2] tripped: failed to connect to n2 at c4ff208bedd9:26257: initial connection heartbeat failed: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = "transport: Error while dialing dial tcp 192.168.208.7:26257: connect: connection refused"
I200430 17:14:59.693787 1987 vendor/github.com/cockroachdb/circuitbreaker/circuitbreaker.go:447  [n1] circuitbreaker: rpc [::]:26257 [n2] event: BreakerTripped
I200430 17:14:59.702537 1987 rpc/nodedialer/nodedialer.go:160  [ct-client] unable to connect to n2: failed to connect to n2 at c4ff208bedd9:26257: initial connection heartbeat failed: rpc error: code = Unavailable desc = all SubConns are in TransientFailure, latest connection error: connection error: desc = "transport: Error while dialing dial tcp 192.168.208.7:26257: connect: connection refused"
I200430 17:15:00.247293 1949 util/stop/stopper.go:542  [server drain process] quiescing; tasks left:
1      node.Node: writing summary
1      [async] intent_resolver_ir_batcher
1      [async] intent_resolver_gc_batcher
1      [async] closedts-subscription
1      [async] closedts-rangefeed-subscriber
I200430 17:15:00.254135 1949 util/stop/stopper.go:542  [server drain process] quiescing; tasks left:
1      node.Node: writing summary
1      [async] intent_resolver_gc_batcher
1      [async] closedts-subscription
1      [async] closedts-rangefeed-subscriber
W200430 17:15:00.254953 69 vendor/google.golang.org/grpc/clientconn.go:1206  grpc: addrConn.createTransport failed to connect to {b5564a6f4539:26257 0  <nil>}. Err :connection error: desc = "transport: failed to write client preface: io: read/write on closed pipe". Reconnecting...
I200430 17:15:00.260182 1949 util/stop/stopper.go:542  [server drain process] quiescing; tasks left:
1      node.Node: writing summary
W200430 17:15:00.293047 129 storage/store.go:1530  [n1,s1,r1/1:/{Min-System/NodeL…}] could not gossip first range descriptor: node unavailable; try another peer
W200430 17:15:00.343531 129 storage/store.go:1530  [n1,s1,r1/1:/{Min-System/NodeL…}] could not gossip first range descriptor: node unavailable; try another peer
W200430 17:15:00.438395 129 storage/store.go:1530  [n1,s1,r1/1:/{Min-System/NodeL…}] could not gossip first range descriptor: node unavailable; try another peer
W200430 17:15:00.668527 129 storage/store.go:1530  [n1,s1,r1/1:/{Min-System/NodeL…}] could not gossip first range descriptor: node unavailable; try another peer
I200430 17:15:00.990793 146 storage/queue.go:577  [n1,s1] rate limited in MaybeAdd (gc): node unavailable; try another peer
I200430 17:15:00.996128 146 storage/queue.go:577  [n1,s1] rate limited in MaybeAdd (merge): node unavailable; try another peer
I200430 17:15:01.013948 146 storage/queue.go:577  [n1,s1] rate limited in MaybeAdd (split): node unavailable; try another peer
I200430 17:15:01.020934 146 storage/queue.go:577  [n1,s1] rate limited in MaybeAdd (replicate): node unavailable; try another peer
I200430 17:15:01.044703 146 storage/queue.go:577  [n1,s1] rate limited in MaybeAdd (replicaGC): node unavailable; try another peer
W200430 17:15:01.025584 129 storage/store.go:1530  [n1,s1,r1/1:/{Min-System/NodeL…}] could not gossip first range descriptor: node unavailable; try another peer
I200430 17:15:01.056484 146 storage/queue.go:577  [n1,s1] rate limited in MaybeAdd (raftlog): node unavailable; try another peer
I200430 17:15:01.068871 146 storage/queue.go:577  [n1,s1] rate limited in MaybeAdd (raftsnapshot): node unavailable; try another peer
I200430 17:15:01.091012 146 storage/queue.go:577  [n1,s1] rate limited in MaybeAdd (consistencyChecker): node unavailable; try another peer
I200430 17:15:01.093945 146 storage/queue.go:577  [n1,s1] rate limited in MaybeAdd (timeSeriesMaintenance): node unavailable; try another peer
W200430 17:15:01.314239 404 server/node.go:826  [n1,summaries] health alerts detected: {Alerts:[{StoreID:1 Category:METRICS Description:ranges.underreplicated Value:38}]}
W200430 17:15:01.316083 404 server/node.go:797  [n1,summaries] error recording status summaries: node unavailable; try another peer
I200430 17:15:01.341397 1949 storage/engine/rocksdb.go:762  closing rocksdb instance at "/cockroach/cockroach-data/cockroach-temp930428700"
I200430 17:15:01.467496 1949 storage/engine/rocksdb.go:762  closing rocksdb instance at "/cockroach/cockroach-data"
I200430 17:15:01.705188 1 cli/start.go:976  server drained and shutdown completed
